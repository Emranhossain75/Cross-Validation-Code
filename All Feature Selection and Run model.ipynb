{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Import "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n\nfrom scipy.stats import chisquare\n\nfrom sklearn.impute import SimpleImputer\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.model_selection import cross_val_score\n\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_auc_score, roc_curve, auc\n%matplotlib inline\n\n%pylab inline\n\nimport pandas as pd\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Upload Data"},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ndf_wine = pd.read_csv(\"../input/hr-analytics/HR_comma_sep.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine.columns = ['satisfaction_level','last_evaluation','number_project',\n        'average_montly_hours','time_spend_company','Work_accident','left',\n        'promotion_last_5years','Department','salary']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine.tail(100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine.isnull()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check Null Value"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine.isnull().values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('left', np.unique(df_wine['left']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_wine[\"left\"].value_counts())\n(df_wine[\"left\"].value_counts() * 100) / 768","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_true = len(df_wine.loc[df_wine['left'] == True])\nnum_false = len(df_wine.loc[df_wine['left'] == False])\nprint (\"Number of left Cases: {0} ({1:2.2f}%)\".format(num_true, (num_true / (num_true + num_false)) * 100))\nprint (\"Number of not left Cases: {0} ({1:2.2f}%)\".format(num_false, (num_true / (num_true + num_false)) * 100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine[\"left\"].value_counts().plot.bar()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HeatMap generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(18, 12))\nsns.heatmap(df_wine.corr(), cmap=\"RdYlBu\", annot=True, fmt=\".1f\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nplt.figure(figsize=(20, 6))\nsns.boxplot(data = df_wine)\nplt.xticks(rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Import label encoder salary"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import label encoder \nfrom sklearn import preprocessing \n  \n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder() \n  \n# Encode labels in column 'salary'. \ndf_wine['salary']= label_encoder.fit_transform(df_wine['salary']) \n  \ndf_wine['salary'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# label encoder Department"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import label encoder \nfrom sklearn import preprocessing \n  \n# label_encoder object knows how to understand word labels. \nlabel_encoder = preprocessing.LabelEncoder() \n  \n# Encode labels in column 'Department'. \ndf_wine['Department']= label_encoder.fit_transform(df_wine['Department']) \n  \ndf_wine['Department'].unique() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_wine.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SCALING"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20, 6))\nsns.boxplot(data = df_wine)\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = df_wine.iloc[:,[0,1,2,3,4,5,6,7,8,9]].values\nstandarscler = preprocessing.StandardScaler()\nx_scaler = standarscler.fit_transform(features)\nprint(x_scaler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20, 6))\nsns.boxplot(data = x_scaler)\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler \nscaler = StandardScaler() \n  \n# To scale data \nscaler.fit(df_wine) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfeature_column_names = ['satisfaction_level','last_evaluation','average_montly_hours','promotion_last_5years','Department']\npredicted_class_name = ['left']\n\n# Getting feature variable values\nX = df_wine[feature_column_names].values\ny = df_wine[predicted_class_name].values\n\n# Splitting using scikit-learn train_test_split function\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 17)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(X_test), len(X_train)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# RandomForestClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performance Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model =  RandomForestClassifier(random_state=42 ,n_estimators=100 , criterion='gini' , max_features='auto',class_weight=None,\n                                 n_jobs=None , verbose=0, warm_start=False)\n\nrf_model.fit(X_train, y_train.ravel())\n\nrf_predict_train = rf_model.predict(X_train)\n\nrf_accuracy = metrics.accuracy_score(y_train, rf_predict_train)\nprint (\"Accuracy: {0:.4f}\".format(rf_accuracy))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Performance Testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_predict_test = rf_model.predict(X_test)\n\nrf_accuracy_testdata = metrics.accuracy_score(y_test, rf_predict_test)\nprint (\"Accuracy: {0:.4f}\".format(rf_accuracy_testdata))\n\nprint (\"Confusion Matrix for Random Forest\")\nprint (\"{0}\".format(metrics.confusion_matrix(y_test, rf_predict_test, labels=[1, 0])))\nprint (\"\")\nprint (\"Classification Report\\n\")\nprint (\"{0}\".format(metrics.classification_report(y_test, rf_predict_test, labels=[1, 0])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# libraries\nfrom mpl_toolkits.mplot3d import Axes3D\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns; sns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.datasets import make_blobs\n\nX, y = make_blobs(n_samples=300, centers=4,\n                  random_state=0, cluster_std=1.0)\nplt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create GaussianNBr model object and train it with the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create GaussianNBr model object and train it with the data\nfrom sklearn.naive_bayes import GaussianNB\nnb_model= GaussianNB()\nnb_model.fit(X_train, y_train.ravel())  # ravel() return 1-D array","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get current accuracy of the model\nprediction_from_trained_data = nb_model.predict(X_train)\naccuracy = metrics.accuracy_score(y_train, prediction_from_trained_data)\nprint (\"Training Accuracy of our GaussianNB model is : {0:.4f}\".format(accuracy))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this returns array of predicted results from test_data\nprediction_from_test_data = nb_model.predict(X_test)\n\naccuracy = metrics.accuracy_score(y_test, prediction_from_test_data)\n\nprint (\"Test Accuracy of our GaussianNB model is: {0:0.4f} %\".format(accuracy))\n\n\nprint (\"Confusion Matrix\")\nprint (\"{0}\".format(metrics.confusion_matrix(y_test, prediction_from_test_data, labels=[1, 0])))\n\nprint (\"Classification Report\")\n# labels for set 1=True to upper left and 0 = False to lower right\nprint (\"{0}\".format(metrics.classification_report(y_test, prediction_from_test_data, labels=[1, 0])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = make_blobs(n_samples=300, centers=4,\n                  random_state=0, cluster_std=1.0)\nplt.scatter(X[:, 0], X[:, 1], c=y, s=50, cmap='rainbow');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"#decision tree\nfrom sklearn import tree\ndt = tree.DecisionTreeClassifier(random_state=0,criterion = \"gini\")\ndt.fit(X_train, y_train)\ndt_score_train = dt.score(X_train, y_train)\nprint(\"Training score: \",dt_score_train)\ndt_score_test = dt.score(X_test, y_test)\nprint(\"Testing score: \",dt_score_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(criterion='entropy',random_state=17)\n\n# Train Decision Tree Classifer\nclf = clf.fit(X_train,y_train)\n\n#Predict the response for test dataset\ny_pred = clf.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn import tree\ndt = tree.DecisionTreeClassifier(criterion='entropy',random_state=17)\n\n\ndt.fit(X_train, y_train.ravel())\n\ndt_score_train = dt.predict(X_train)\n\ndt_accuracy = metrics.accuracy_score(y_train, dt_score_train)\nprint (\"Accuracy: {0:.4f}\".format(dt_accuracy))\n\n\n#dt.fit(X_train, y_train)\n#dt_score_train = dt.score(X_train, y_train)\n#print(\"Training score: \",dt_score_train)\n#dt_score_test = dt.score(X_test, y_test)\n#print(\"Testing score: \",dt_score_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_score_test = dt.predict(X_test)\n\ndt_score_testdata = metrics.accuracy_score(y_test, dt_score_test)\nprint (\"Accuracy: {0:.4f}\".format(dt_score_testdata))\n\nprint (\"Confusion Matrix for Random Forest\")\nprint (\"{0}\".format(metrics.confusion_matrix(y_test, dt_score_test, labels=[1, 0])))\nprint (\"\")\nprint (\"Classification Report\\n\")\nprint (\"{0}\".format(metrics.classification_report(y_test, dt_score_test, labels=[1, 0])))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LogisticRegression model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nLogisticRegression(penalty='l1')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logis = LogisticRegression()\nlogis.fit(X_train, y_train)\nlogis_score_train = logis.score(X_train, y_train)\nprint(\"Training score: \",logis_score_train)\nlogis_score_test = logis.score(X_test, y_test)\nprint(\"Testing score: \",logis_score_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNeighborsClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors=1)\nknn.fit(X_train, y_train)\nknn_accuracy=knn.score(X_train, y_train)\nprint('Training accuracy:',knn_accuracy )\nknn_accuracy_testdata = knn.score(X_test, y_test)\nprint('Test accuracy:',knn_accuracy_testdata )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SVM Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\nsvm = SVC()\nsvm.probability = True\nsvm.fit(X_train, y_train)\nsvm_score_train = svm.score(X_train, y_train)\nprint(\"Training score: \",svm_score_train)\nsvm_score_test = svm.score(X_test, y_test)\nprint(\"Testing score: \",svm_score_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# All Comparison"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model comparison\nmodels = pd.DataFrame({\n        'Model'          : ['Logistic Regression', 'SVM', 'kNN', 'Decision Tree', 'Random Forest','GaussianNB'],\n        'Training_Score' : [logis_score_train, svm_score_train, knn_accuracy, dt_accuracy, rf_accuracy, accuracy],\n        'Testing_Score'  : [logis_score_test, svm_score_test, knn_accuracy_testdata, dt_score_testdata, rf_accuracy_testdata,accuracy ]\n    })\nmodels.sort_values(by='Testing_Score', ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nX = [[0., 0.], [0., 1.], [1., 0.], [1., 1.]]\ny = [0, 0, 0, 1]\nclf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n                    hidden_layer_sizes=(5, 2), random_state=1)\nprint(clf.fit(X, y))      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"weights between input and first hidden layer:\")\nprint(clf.coefs_[0])\nprint(\"\\nweights between first hidden and second hidden layer:\")\nprint(clf.coefs_[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"w0 = \", clf.coefs_[0][0][0])\nprint(\"w1 = \", clf.coefs_[0][1][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf.coefs_[0][:,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(len(clf.coefs_)):\n    number_neurons_in_layer = clf.coefs_[i].shape[1]\n    for j in range(number_neurons_in_layer):\n        weights = clf.coefs_[i][:,j]\n        print(i, j, weights, end=\", \")\n        print()\n    print()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Bias values for first hidden layer:\")\nprint(clf.intercepts_[0])\nprint(\"\\nBias values for second hidden layer:\")\nprint(clf.intercepts_[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = clf.predict([[0, 0], [0, 1], \n                      [1, 0], [0, 1], \n                      [1, 1], [2., 2.],\n                      [1.3, 1.3], [2, 4.8]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prob_results = clf.predict_proba([[0, 0], [0, 1], \n                                  [1, 0], [0, 1], \n                                  [1, 1], [2., 2.], \n                                  [1.3, 1.3], [2, 4.8]])\nprint(prob_results)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Another mlp"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom matplotlib import pyplot as plt\nnpoints = 50\nX, Y = [], []\n# class 0\nX.append(np.random.uniform(low=-2.5, high=2.3, size=(npoints,)) )\nY.append(np.random.uniform(low=-1.7, high=2.8, size=(npoints,)))\n# class 1\nX.append(np.random.uniform(low=-7.2, high=-4.4, size=(npoints,)) )\nY.append(np.random.uniform(low=3, high=6.5, size=(npoints,)))\nlearnset = []\nlearnlabels = []\nfor i in range(2):\n    # adding points of class i to learnset\n    points = zip(X[i], Y[i])\n    for p in points:\n        learnset.append(p)\n        learnlabels.append(i)\nnpoints_test = 3 * npoints\nTestX = np.random.uniform(low=-7.2, high=5, size=(npoints_test,)) \nTestY = np.random.uniform(low=-4, high=9, size=(npoints_test,))\ntestset = []\npoints = zip(TestX, TestY)\nfor p in points:\n    testset.append(p)\ncolours = [\"b\", \"r\"]\nfor i in range(2):\n    plt.scatter(X[i], Y[i], c=colours[i])\nplt.scatter(TestX, TestY, c=\"g\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom sklearn.datasets import fetch_mldata\nfrom sklearn.neural_network import MLPClassifier\nmlp = MLPClassifier(hidden_layer_sizes=(20, 3), max_iter=150, alpha=1e-4,\n                    solver='sgd', verbose=10, tol=1e-4, random_state=1,\n                    learning_rate_init=.1)\nmlp.fit(learnset, learnlabels)\nprint(\"Training set score: %f\" % mlp.score(learnset, learnlabels))\nprint(\"Test set score: %f\" % mlp.score(learnset, learnlabels))\nmlp.classes_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"array([0, 1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = clf.predict(testset)\npredictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testset = np.array(testset)\ntestset[predictions==1]\ncolours = ['#C0FFFF', \"#FFC8C8\"]\nfor i in range(2):\n    plt.scatter(X[i], Y[i], c=colours[i])\ncolours = [\"b\", \"r\"]\nfor i in range(2):\n    cls = testset[predictions==i]\n    Xt, Yt = zip(*cls)\n    plt.scatter(Xt, Yt, marker=\"D\", c=colours[i])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MLP = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,\n                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MLP.fit(X_train, y_train)\ny_pred = MLP.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cl = accuracy_score(y_test, y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(cl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final ANN(MLP)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_wine.iloc[:,:-1]\ny = df_wine.iloc[:,-1:]  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = Sequential()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu', input_dim = X.shape[1]))\nclassifier.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'relu'))\nclassifier.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\nclassifier.compile(optimizer = 'adam', loss = 'mean_squared_error', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nclassifier.fit(X_train, y_train, batch_size = 15, epochs = 100, validation_split=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(nrows = 2, ncols = 3, figsize = (15, 4))\nfig, ax_arr = plt.subplots(nrows = 3, ncols = 3, figsize = (25,15))\n\n#LOGMODEL\nprobs = logis.predict_proba(X_test)\npreds = probs[:,1]\nfprlog, tprlog, thresholdlog = metrics.roc_curve(y_test, preds)\nroc_auclog = metrics.auc(fprlog, tprlog)\n\nax_arr[0,0].plot(fprlog, tprlog, 'b', label = 'AUC = %0.2f' % roc_auclog)\nax_arr[0,0].plot([0, 1], [0, 1],'r--')\nax_arr[0,0].set_title('Receiver Operating Characteristic Logistic ',fontsize=20)\nax_arr[0,0].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,0].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,0].legend(loc = 'lower right', prop={'size': 16})\n\n#RANDOM FOREST --------------------\nprobs = rf_model.predict_proba(X_test)\npreds = probs[:,1]\nfprrfc, tprrfc, thresholdrfc = metrics.roc_curve(y_test, preds)\nroc_aucrfc = metrics.auc(fprrfc, tprrfc)\n\nax_arr[0,1].plot(fprrfc, tprrfc, 'b', label = 'AUC = %0.2f' % roc_aucrfc)\nax_arr[0,1].plot([0, 1], [0, 1],'r--')\nax_arr[0,1].set_title('Receiver Operating Characteristic Random Forest ',fontsize=20)\nax_arr[0,1].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,1].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,1].legend(loc = 'lower right', prop={'size': 16})\n\n\n#KNN----------------------\nprobs = knn.predict_proba(X_test)\npreds = probs[:,1]\nfprknn, tprknn, thresholdknn = metrics.roc_curve(y_test, preds)\nroc_aucknn = metrics.auc(fprknn, tprknn)\n\nax_arr[0,2].plot(fprknn, tprknn, 'b', label = 'AUC = %0.2f' % roc_aucknn)\nax_arr[0,2].plot([0, 1], [0, 1],'r--')\nax_arr[0,2].set_title('Receiver Operating Characteristic KNN ',fontsize=20)\nax_arr[0,2].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[0,2].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[0,2].legend(loc = 'lower right', prop={'size': 16})\n\n#DECISION TREE ---------------------\nprobs = dt.predict_proba(X_test)\npreds = probs[:,1]\nfprdtree, tprdtree, thresholddtree = metrics.roc_curve(y_test, preds)\nroc_aucdtree = metrics.auc(fprdtree, tprdtree)\n\nax_arr[1,0].plot(fprdtree, tprdtree, 'b', label = 'AUC = %0.2f' % roc_aucdtree)\nax_arr[1,0].plot([0, 1], [0, 1],'r--')\nax_arr[1,0].set_title('Receiver Operating Characteristic Decision Tree ',fontsize=20)\nax_arr[1,0].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,0].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,0].legend(loc = 'lower right', prop={'size': 16})\n\n#MLP ---------------------\nprobs = MLP.predict_proba(X_test)\npreds = probs[:,1]\nfprmlp, tprmlp, thresholdmlp = metrics.roc_curve(y_test, preds)\nroc_aucmlp = metrics.auc(fprmlp, tprmlp)\n\nax_arr[2,0].plot(fprmlp, tprmlp, 'b', label = 'AUC = %0.2f' % roc_aucmlp)\nax_arr[2,0].plot([0, 1], [0, 1],'r--')\nax_arr[2,0].set_title('Receiver Operating Characteristic MLP ',fontsize=20)\nax_arr[2,0].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[2,0].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[2,0].legend(loc = 'lower right', prop={'size': 16})\n\n#SVM ---------------------\nprobs = svm.predict_proba(X_test)\npreds = probs[:,1]\nfprmlp, tprmlp, thresholdmlp = metrics.roc_curve(y_test, preds)\nroc_aucsvm = metrics.auc(fprmlp, tprmlp)\n\nax_arr[2,1].plot(fprmlp, tprmlp, 'b', label = 'AUC = %0.2f' % roc_aucsvm)\nax_arr[2,1].plot([0, 1], [0, 1],'r--')\nax_arr[2,1].set_title('Receiver Operating Characteristic SVM ',fontsize=20)\nax_arr[2,1].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[2,1].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[2,1].legend(loc = 'lower right', prop={'size': 16})\n\n\n#GAUSSIAN ---------------------\nprobs = nb_model.predict_proba(X_test)\npreds = probs[:,1]\nfprgau, tprgau, thresholdgau = metrics.roc_curve(y_test, preds)\nroc_aucgau = metrics.auc(fprgau, tprgau)\n\nax_arr[1,1].plot(fprgau, tprgau, 'b', label = 'AUC = %0.2f' % roc_aucgau)\nax_arr[1,1].plot([0, 1], [0, 1],'r--')\nax_arr[1,1].set_title('Receiver Operating Characteristic Gaussian ',fontsize=20)\nax_arr[1,1].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,1].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,1].legend(loc = 'lower right', prop={'size': 16})\n\n#ALL PLOTS ----------------------------------\nax_arr[1,2].plot(fprgau, tprgau, 'b', label = 'Gaussian= %0.2f' % roc_aucgau, color='black')\nax_arr[1,2].plot(fprdtree, tprdtree, 'b', label = 'Decision Tree= %0.2f' % roc_aucdtree, color='blue')\nax_arr[1,2].plot(fprknn, tprknn, 'b', label = 'Knn = %0.2f' % roc_aucknn, color='brown')\nax_arr[1,2].plot(fprrfc, tprrfc, 'b', label = 'Random Forest = %0.2f' % roc_aucrfc, color='green')\nax_arr[1,2].plot(fprlog, tprlog, 'b', label = 'Logistic = %0.2f' % roc_auclog, color='grey')\nax_arr[1,2].plot(fprlog, tprlog, 'b', label = 'MLP =  %0.2f ' %97.21, color='yellow')\nax_arr[1,2].plot(fprlog, tprlog, 'b', label = 'SVM =  %0.2f ' %roc_aucsvm , color='red')\nax_arr[1,2].set_title('Receiver Operating Comparison ',fontsize=20)\nax_arr[1,2].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,2].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,2].legend(loc = 'lower right', prop={'size': 16})\n\nplt.subplots_adjust(wspace=0.2)\nplt.tight_layout() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax_arr = plt.subplots(nrows = 2, ncols = 3, figsize = (25,15))\n\nax_arr[1,1].plot(fprgau, tprgau, 'b', label = 'AUC = %0.2f' % roc_aucgau)\nax_arr[1,1].plot([0, 1], [0, 1],'r--')\nax_arr[1,1].set_title('Receiver Operating Characteristic Gaussian ',fontsize=20)\nax_arr[1,1].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,1].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,1].legend(loc = 'lower right', prop={'size': 16})\n\nax_arr[1,2].plot(fprgau, tprgau, 'b', label = 'Gaussian= %0.2f' % roc_aucgau, color='black')\nax_arr[1,2].plot(fprdtree, tprdtree, 'b', label = 'Decision Tree= %0.2f' % roc_aucdtree, color='blue')\nax_arr[1,2].plot(fprknn, tprknn, 'b', label = 'Knn = %0.2f' % roc_aucknn, color='brown')\nax_arr[1,2].plot(fprrfc, tprrfc, 'b', label = 'Random Forest = %0.2f' % roc_aucrfc, color='green')\n\nax_arr[1,2].plot(fprlog, tprlog, 'b', label = 'MLP =  %0.2f ' %0.80, color='yellow')\nax_arr[1,2].plot(fprlog, tprlog, 'b', label = 'SVM =  %0.2f ' %roc_aucsvm , color='red')\nax_arr[1,2].set_title('Receiver Operating Comparison ',fontsize=20)\nax_arr[1,2].set_ylabel('True Positive Rate',fontsize=20)\nax_arr[1,2].set_xlabel('False Positive Rate',fontsize=15)\nax_arr[1,2].legend(loc = 'lower right', prop={'size': 16})\n\nplt.subplots_adjust(wspace=0.2)\nplt.tight_layout() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}